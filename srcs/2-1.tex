\subsection{动态环境下静态部分地图的构建} motion removal
\label{subsec:object-centered_mapping}
\newpage
由于便携的消费级深度传感器的出现，室内场景的稠密视觉SLAM在近些年取得了不错的进展。KinectFusion~\cite{kinectFusion}首次利用RGBD数据实现了实时的稠密定位和数据融合，并在场景尺度~\cite{voxelHashing}、回环调整~\cite{kintinuous}以及计算效率~\cite{CPUmapping}上有着一系列的拓展。这类方法建立在场景完全静态的严格假设下。而对于存在运动物体的场景，动态的观测数据违反了配准能量函数的基本假设，需要被视为离群点从地图中剔除。若是运动物体区域的点云数据被融合到三维地图中，将会带来系统不可逆的崩塌。

在视觉SLAM应用于稠密建图的这一方向，一个主要的策略就是只维护静态部分的地图。相应地，应对运动物体的挑战主要包括如何避免将运动部分的数据融入地图，以及如何补全地图中因为运动物体遮挡而未被获取的数据。通过维护一个高质量、可服用的静态地图，相机位姿估计可以在静态世界的假设中鲁棒地进行估计，而如果运动部分数据没有被很好地消除，用于定位的地图信息就会使问题变得复杂起来。

ElasticFusion~\cite{elasticFusion}可以应对画面中存在少量运动物体的场景。算法并未显式地检测运动物体，而是将动态环境下的稠密重建作为一个鲁棒估计问题，通过统计的方式自主地将动态区域作为外点剔除。在这个工作的基础上，\cite{keller13_3dv} 从重建的角度出发，认为每个面元只有在多个连续帧被反复观测到才可以融合到三维模型中。当输入的点云数据与匹配上的地图点位置距离过远时，这部分点云会被作为种子点，通过区域生长将当前帧分割成静态和动态区域。相应地，地图上与动态区域有着匹配关系的部分将从地图上剔除掉。通过这种不断更新地图的方式，当之前静态的物体发生运动时，系统可以有效地检测出运动状态的变化，以消除这部分数据对系统鲁棒性的影响。

BaMVO~\cite{BaMVO} 利用背景提取领域(background subtraction)广泛使用的非参数化背景模型进行稠密视觉里程计估计。通过存储连续的4帧深度图并对齐到同一个视角，背景区域可以根据多帧对齐后的深度值差异来进行判别。这样的多帧判别方法建立了时域上的连续性，但是由于采用帧到帧（frame-to-frame）的定位策略，BaMVO不可避免地引入了累计误差。

BaMVO说明时序多帧的反馈对动态环境下有效的运动物体检测与分割至关重要，而StaticFusion~\cite{staticFusion}认为有效地时序信息传播可以通过维护一个只包含场景中静态部分的三维地图来实现。通过三维数据融合，这种长时的时序信息不会带来额外的计算代价。通过同时检测运动物体并重建静态环境，staticFusion实现了动态环境下的鲁棒稠密的RGBD SLAM。点云数据被聚类到一个个聚类簇中，每个聚类簇再进行运动状态估计和刚体运动估计的联合求解，以获得每个聚类簇属于静态或动态的概率。被判定为静态的聚类簇内数据会被融合到静态地图中，而被判定动态的聚类簇会进行场景流估计，以实现运动物体时序上的信息传递。由于采用了帧到模型（frame-to-model）的定位策略，相机位姿估计可以有效地消除由于累计误差带来的漂移。

DynaSLAM~\cite{DynaSLAM}提出了一种在线的算法，可以同时在单目、双目和RGBD相机设定下应对环境中的运动物体。整个系统建立在ORB-SLAM~\cite{orbslam2}的前端基础上，而核心出发点是通过建立可复用的三维地图进行更加精确的相机位姿估计。对于单目相机和双目相机，DynaSLAM采用卷积神经网络（CNN）进行像素级的物体分割，作为运动状态估计的先验。在RGBD相机的设定下，DynaSLAM则结合了多目立体视觉和深度学习的算法进行运动物体检测。


